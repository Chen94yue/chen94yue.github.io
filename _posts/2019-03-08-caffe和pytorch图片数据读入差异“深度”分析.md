---
layout:     
title:      Caffeå’ŒPytorchå›¾ç‰‡æ•°æ®è¯»å…¥å·®å¼‚â€œæ·±åº¦â€åˆ†æ
subtitle:   fuck you Caffe
date:       2019-03-08
author:     Shaozi
header-img: 
catalog: true
tags:
    - Caffe
    - Pytorch
---

é—®é¢˜èƒŒæ™¯ï¼š
	â€”â€”â€”â€”è¿‘æœŸå·¥ç¨‹ä¸Šç¢°åˆ°è¿™æ ·ä¸€ä¸ªæƒ…å†µï¼Œç”¨pytorchè®­ç»ƒçš„æ¨¡å‹ï¼Œåœ¨å°†ç½‘ç»œå‚æ•°è½¬ä¸ºcaffemodelä¹‹åï¼Œåœ¨caffeä¸‹ä¸èƒ½å¤ç°å…¶æ€§èƒ½ï¼Œæ•´ä½“è¯„ä»·æŒ‡æ ‡ä¸Šå·®äº†ç™¾åˆ†ä¹‹ä¸€ç‚¹å‡ ã€‚

ä¸ºäº†åˆ¤æ–­åˆ°åº•æ˜¯ä»€ä¹ˆä½ç½®å‡ºç°äº†é—®é¢˜ã€‚å¸ˆå…„é¦–å…ˆåšäº†æ§åˆ¶å˜é‡çš„åˆ†æã€‚å»æ‰datalayerï¼Œç›´æ¥é€å…¥ä¸€ä¸ªè‡ªå®šä¹‰çš„çŸ©é˜µç»™åé¢çš„ç½‘ç»œã€‚Pytorchå’ŒCaffeè¾“å‡ºç»“æœç›¸åŒã€‚å› æ­¤å°†é—®é¢˜èšç„¦åœ¨caffeçš„datalayerä¸Šã€‚æ¥ä¸‹æ¥çš„å·¥ä½œäº¤ç»™æˆ‘æ¥åšã€‚

ä¸ºäº†ç®€åŒ–åˆ†ææˆæœ¬ï¼Œæˆ‘ä»¬åªä½¿ç”¨datalayeråšä»¥ä¸‹å‡ ä¸ªç®€å•çš„æ“ä½œï¼š
1. è¯»å–å›¾ç‰‡
2. Resizeå›¾ç‰‡
3. Normalize

æˆ‘ä»¬ä½¿ç”¨å¦‚ä¸‹å›¾ç‰‡ï¼ˆå‡ºè‡ª[CUB-200-2011 dataset](http://www.vision.caltech.edu/visipedia/CUB-200-2011.html)ï¼‰è¿›è¡Œæµ‹è¯•ï¼š
![TestImage](https://i.loli.net/2019/03/08/5c822951d5640.jpg)

Pytorchç”¨æˆ·é€šå¸¸ä½¿ç”¨çš„æ˜¯torchvisionä¸‹çš„transformså‡½æ•°åŒ…å¯¹å›¾åƒè¿›è¡Œæ“ä½œã€‚è¯¥éƒ¨åˆ†ä»£ç å¦‚ä¸‹ï¼š
```python
import torchvision
import torchvision.transforms as transforms
import PIL.Image as Image

img = pil_loader('American_Redstart_0064_103081.jpg')
trans = transforms.Compose([
        transforms.Resize((224,224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
        ])
```
é¦–å…ˆæˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹Resizeçš„å®ç°æ–¹æ³•ï¼Œæºç ä¸ºï¼š
```python
def resize(img, size, interpolation=Image.BILINEAR):
    r"""Resize the input PIL Image to the given size.

    Args:
        img (PIL Image): Image to be resized.
        size (sequence or int): Desired output size. If size is a sequence like
            (h, w), the output size will be matched to this. If size is an int,
            the smaller edge of the image will be matched to this number maintaing
            the aspect ratio. i.e, if height > width, then image will be rescaled to
            :math:`\left(\text{size} \times \frac{\text{height}}{\text{width}}, \text{size}\right)`
        interpolation (int, optional): Desired interpolation. Default is
            ``PIL.Image.BILINEAR``

    Returns:
        PIL Image: Resized image.
    """
    if not _is_pil_image(img):
        raise TypeError('img should be PIL Image. Got {}'.format(type(img)))
    if not (isinstance(size, int) or (isinstance(size, Iterable) and len(size) == 2)):
        raise TypeError('Got inappropriate size arg: {}'.format(size))

    if isinstance(size, int):
        w, h = img.size
        if (w <= h and w == size) or (h <= w and h == size):
            return img
        if w < h:
            ow = size
            oh = int(size * h / w)
            return img.resize((ow, oh), interpolation)
        else:
            oh = size
            ow = int(size * w / h)
            return img.resize((ow, oh), interpolation)
    else:
        return img.resize(size[::-1], interpolation)
```
æ ¸å¿ƒè¯­å¥å¾ˆç®€å•ï¼Œåœ¨å¯¹äºè¾“å…¥çš„å‚æ•°åšäº†ç®€å•çš„åˆ¤æ–­å’Œè½¬æ¢ä¹‹åï¼Œè°ƒç”¨äº†PILåº“çš„resizeå‡½æ•°ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¿™é‡Œä½¿ç”¨çš„é»˜è®¤çš„å·®å€¼æ–¹æ³•ä¸ºåŒçº¿æ€§å·®å€¼ï¼ˆPIL.Image.BILINEARï¼‰ã€‚çœ‹åˆ°è¿™é‡Œå°±å·²ç»è¶³å¤Ÿäº†ï¼Œä¸ç”¨å†å»çœ‹PILä¸­resizeæ˜¯å¦‚ä½•å®ç°çš„ï¼Œå› ä¸ºPILå¥½åƒæ²¡æœ‰å®Œå…¨å¼€æºï¼Ÿï¼Ÿï¼Ÿï¼ˆæˆ‘æ²¡æœ‰æ‰¾åˆ°æºç ï¼‰

ä¹‹åtotensorçš„å®ç°æ–¹æ³•ä¸ºï¼š
```python
def to_tensor(pic):
    """Convert a ``PIL Image`` or ``numpy.ndarray`` to tensor.

    See ``ToTensor`` for more details.

    Args:
        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.

    Returns:
        Tensor: Converted image.
    """
    if not(_is_pil_image(pic) or _is_numpy_image(pic)):
        raise TypeError('pic should be PIL Image or ndarray. Got {}'.format(type(pic)))

    if isinstance(pic, np.ndarray):
        # handle numpy array
        if pic.ndim == 2:
            pic = pic[:, :, None]

        img = torch.from_numpy(pic.transpose((2, 0, 1)))
        # backward compatibility
        if isinstance(img, torch.ByteTensor):
            return img.float().div(255)
        else:
            return img

    if accimage is not None and isinstance(pic, accimage.Image):
        nppic = np.zeros([pic.channels, pic.height, pic.width], dtype=np.float32)
        pic.copyto(nppic)
        return torch.from_numpy(nppic)

    # handle PIL Image
    if pic.mode == 'I':
        img = torch.from_numpy(np.array(pic, np.int32, copy=False))
    elif pic.mode == 'I;16':
        img = torch.from_numpy(np.array(pic, np.int16, copy=False))
    elif pic.mode == 'F':
        img = torch.from_numpy(np.array(pic, np.float32, copy=False))
    elif pic.mode == '1':
        img = 255 * torch.from_numpy(np.array(pic, np.uint8, copy=False))
    else:
        img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))
    # PIL image mode: L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK
    if pic.mode == 'YCbCr':
        nchannel = 3
    elif pic.mode == 'I;16':
        nchannel = 1
    else:
        nchannel = len(pic.mode)
    img = img.view(pic.size[1], pic.size[0], nchannel)
    # put it from HWC to CHW format
    # yikes, this transpose takes 80% of the loading time/CPU
    img = img.transpose(0, 1).transpose(0, 2).contiguous()
    if isinstance(img, torch.ByteTensor):
        return img.float().div(255)
    else:
        return img
```
å¯ä»¥çœ‹åˆ°å¯¹äºè¾“å…¥çš„PILç±»å‹çš„å›¾ç‰‡ï¼Œto_tensorå‡½æ•°é¦–å…ˆä¾æ®å…¶ä¸åŒçš„å›¾ç‰‡ç»“æ„è¿›è¡Œè½¬æ¢ï¼Œç„¶åæ¯ä¸€ä¸ªåƒç´ é™¤255å°†å…¶å½’ä¸€åŒ–åˆ°[0,1],è¿™ä¹Ÿå°±æ˜¯åé¢Normalizeéƒ¨åˆ†éƒ½æ˜¯å°æ•°çš„åŸå› ã€‚
ç”±äºNormalizeä¸ºçº¯æ•°å­—è®¡ç®—ï¼Œå‰é¢çš„æ•°å€¼ä¸ºæ¯ä¸€ä¸ªå›¾åƒé€šé“çš„å‡å€¼ï¼Œåé¢çš„æ•°å€¼ä¸ºçŠ¶æ€å€¼ã€‚æºç ä¸­çš„è®¡ç®—å…¬å¼ä¸ºï¼š
```python
def normalize(tensor, mean, std, inplace=False):
    """Normalize a tensor image with mean and standard deviation.

    .. note::
        This transform acts out of place by default, i.e., it does not mutates the input tensor.

    See :class:`~torchvision.transforms.Normalize` for more details.

    Args:
        tensor (Tensor): Tensor image of size (C, H, W) to be normalized.
        mean (sequence): Sequence of means for each channel.
        std (sequence): Sequence of standard deviations for each channely.

    Returns:
        Tensor: Normalized Tensor image.
    """
    if not _is_tensor_image(tensor):
        raise TypeError('tensor is not a torch image.')

    if not inplace:
        tensor = tensor.clone()

    mean = torch.tensor(mean, dtype=torch.float32)
    std = torch.tensor(std, dtype=torch.float32)
    tensor.sub_(mean[:, None, None]).div_(std[:, None, None])
    return tensor
```
å¯ä»¥çœ‹åˆ°æ˜¯å‡å»å‡å€¼ä¹‹åå†é™¤çŠ¶æ€å€¼ã€‚

æ¥ä¸‹æ¥æˆ‘ä»¬æ¥çœ‹caffeçš„å®ç°ï¼Œcaffeè¿™è¾¹é¦–å…ˆå®šä¹‰ç½‘ç»œçš„prototxtæ–‡ä»¶ï¼Œå› ä¸ºæˆ‘ä»¬ä¸éœ€è¦åé¢çš„ç½‘ç»œï¼Œprototxtæ–‡ä»¶åªåŒ…å«ä¸€å±‚ç½‘ç»œï¼š
```c++
layer {
  name: "Data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  image_data_param {
    source: "demo.txt"
    root_folder: "./"
    new_height: 224
    new_width: 224
    is_color: true
    batch_size: 1
  }
}
```
image data layerçš„ä»£ç å°±é•¿äº†ï¼Œè¿™é‡Œå°±èŠ‚é€‰ä¸€ä¸‹å…³é”®çš„éƒ¨åˆ†æ”¾åœ¨è¿™é‡Œ(åªçœ‹.cppæ–‡ä»¶å§)ï¼š
```c++
cv::Mat cv_img = ReadImageToCVMat(root_folder + lines_[lines_id_].first,new_height, new_width, is_color);
CHECK(cv_img.data) << "Could not load " << lines_[lines_id_].first;
read_time += timer.MicroSeconds();
timer.Start();
// Apply transformations (mirror, crop...) to the image
int offset = batch->data_.offset(item_id);
this->transformed_data_.set_cpu_data(prefetch_data + offset);
this->data_transformer_->Transform(cv_img, &(this->transformed_data_));
trans_time += timer.MicroSeconds();//ç»Ÿè®¡é¢„å¤„ç†æ—¶é—´
```
é¦–å…ˆè°ƒç”¨ReadImageToCVMatå‡½æ•°è¯»å…¥å›¾ç‰‡ï¼Œè¯¥å‡½æ•°åœ¨root/caffe/src/caffe/util/io.cppä¸­ã€‚
ä¹‹åè°ƒç”¨äº†data_transformerçš„Transformå‡½æ•°ï¼Œè¯¥å‡½æ•°åœ¨root/caffe/src/caffe/data_transformer.cppä¸­ã€‚
é¦–å…ˆReadImageToCVMatçš„å®ç°ä¸ºï¼š
```c++
cv::Mat ReadImageToCVMat(const string& filename,
    const int height, const int width, const bool is_color) {
  cv::Mat cv_img;
  int cv_read_flag = (is_color ? CV_LOAD_IMAGE_COLOR :
    CV_LOAD_IMAGE_GRAYSCALE);
  cv::Mat cv_img_origin = cv::imread(filename, cv_read_flag);
  if (!cv_img_origin.data) {
    LOG(ERROR) << "Could not open or find file " << filename;
    return cv_img_origin;
  }
  if (height > 0 && width > 0) {
    cv::resize(cv_img_origin, cv_img, cv::Size(width, height));
  } else {
    cv_img = cv_img_origin;
  }
  return cv_img;
}
```
å…³é”®åœ¨äºä¸€å¥ï¼šcv::resize(cv_img_origin, cv_img, cv::Size(width, height));
å¯ä»¥çœ‹åˆ°caffeçš„resizeå‡½æ•°æ˜¯åŸºäºopencvå®ç°çš„ã€‚æŸ¥ä¸€ä¸‹opencvçš„æ–‡æ¡£ï¼Œå¯ä»¥çœ‹åˆ°ï¼Œè¯¥å·®å€¼æ–¹æ³•ä¹Ÿæ˜¯é»˜è®¤åŒçº¿æ€§å·®å€¼ã€‚æœ‰å…´è¶£çš„åŒå­¦å¯ä»¥å»[è¿™é‡Œ](https://docs.opencv.org/master/da/d54/group__imgproc__transform.html#ga47a974309e9102f5f08231edc7e7529d)æŸ¥çœ‹ä¸€ä¸‹ã€‚
å¦å¤–resizeçš„æºç å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/opencv/opencv/blob/332c37f332733e5a2d717fc6eb4d605a304cda70/modules/imgproc/src/resize.cpp)çœ‹åˆ°ã€‚3764è¡Œï¼Œå‘Šè¾ğŸš“ã€‚

Caffeæ²¡æœ‰tensorè¿™ä¸ªä¸œè¥¿ï¼Œæ‰€ä»¥æ¯”Pytorchå°‘äº†ä¸€æ­¥ã€‚æœ€åçœ‹ä¸€ä¸‹caffeçš„Normalizeæ–¹æ³•ï¼š
```c++
if (has_mean_file) {//è‹¥æŒ‡å®šäº†å‡å€¼æ–‡ä»¶
    transformed_data[top_index] =(datum_element - mean[data_index]) * scale;//æ‰§è¡Œå»å‡å€¼ã€å¹…åº¦ç¼©æ”¾
    } 
else {
    if (has_mean_values) {//è‹¥æŒ‡å®šäº†å‡å€¼æ•°å€¼
        transformed_data[top_index] =(datum_element - mean_values_[c]) * scale;//æ‰§è¡Œå»å‡å€¼ã€å¹…åº¦ç¼©æ”¾
    } 
    else {
     transformed_data[top_index] = datum_element * scale;//ä¸å»å‡å€¼ã€åªåšå¹…åº¦ç¼©æ”¾
}
```
çœ‹åˆ°è¿™é‡Œï¼Œç¬¬ä¸€ä¸ªå¯¼è‡´Caffeå’ŒPytorché€å…¥ç½‘ç»œçš„æ•°æ®ä¸åŒçš„åŸå› å‡ºç°äº†â€”â€”â€”â€”Normalizeæ–¹æ³•ä¸åŒã€‚
ä¸‹é¢æˆ‘ä»¬ä»¥Pytorchçš„ä¸ºåŸºå‡†ï¼Œæ¥çœ‹ä¸€ä¸‹Caffeçš„layerå‚æ•°åº”è¯¥å¦‚ä½•è®¾ç½®ã€‚æ¨å¯¼è¿‡ç¨‹å¾ˆç®€å•ï¼Œæˆ‘å°±çœç•¥äº†ï¼Œè¿™é‡Œè®¾Caffeçš„å‚æ•°scaleä¸º1/255ä¸ºå®šå€¼ã€‚mpï¼Œspåˆ†åˆ«ä¸ºPytorchçš„ä¸€ä¸ªé€šé“çš„å‡å€¼å’ŒçŠ¶æ€å€¼ï¼Œmcä¸ºCaffeä¸€ä¸ªé€šé“çš„å‡å€¼ã€‚æˆ‘ä»¬å¯ä»¥å¾—åˆ°ä¸‹é¢çš„å…³ç³»ï¼š
```
æ ¹æœ¬æ¨ä¸å‡ºæ¥ï¼
```
ä½†æ˜¯æˆ‘ä»¬è¿˜æ˜¯å°†scaleè®¾ä¸º1å§ã€‚
æ–°çš„datalayerä¸ºï¼š
```c++
layer {
  name: "Data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_value: ???
    mean_value: ???
    mean_value: ???
    scale: 1/255
  }
  image_data_param {
    source: "demo.txt"
    root_folder: "./"
    new_height: 224
    new_width: 224
    is_color: true
    batch_size: 1
  }
}
```
æ²¡é”™è¿™å°±æ˜¯pytorchçš„ç¬¬ä¸€ä¸ªå‘ï¼Œæˆ‘ä»¬æ ¹æœ¬æ²¡æœ‰åŠæ³•æ‰¾åˆ°å®Œå…¨å¯¹åº”çš„æ–¹æ³•ï¼Œé‚£ä¹ˆæœ‰ä»€ä¹ˆæ–¹æ³•èƒ½å¤Ÿæ”¹å˜å‘¢ï¼Œå…¶å®å¾ˆç®€å•ï¼Œä¿®æ”¹Normalizeå‡½æ•°çš„å®ç°æ–¹å¼å’Œcaffeä¸€æ ·å°±è¡Œäº†ã€‚å½“ç„¶ä¹Ÿå¯ä»¥ä¿®æ”¹caffeçš„å®ç°æ–¹å¼å’Œpytorchä¸€æ ·ã€‚éš¾åº¦ä¸å¤§ã€‚è¿™é‡Œå‡è®¾æˆ‘ä»¬å·²ç»æ”¹ä¸ºä¸€æ ·äº†ï¼Œä¼šæœ‰ä¸‹é¢çš„ç½‘ç»œå®šä¹‰ï¼š
```c++
layer {
  name: "Data"
  type: "ImageDataPytorch"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_value: 0.485
    mean_value: 0.456
    mean_value: 0.406
    std_value: 0.229
    std_value: 0.224
    std_value: 0.225
  }
  image_data_param {
    source: "demo.txt"
    root_folder: "./"
    new_height: 224
    new_width: 224
    is_color: true
    batch_size: 1
  }
}
```
æºç æˆ‘æ‡’å¾—æ”¹äº†ï¼Œå¤§è‡´å°±æ˜¯(pixel_value/225 - mean_value)/std_valueã€‚ä¿æŒå’ŒPytorchä¸€æ ·å°±è¡Œäº†ã€‚

ç»è¿‡ä¸Šé¢çš„ä¿®æ”¹åº”è¯¥ä¸¤ä¸ªè¾“å‡ºä¸€æ ·äº†å§ï¼Ÿæ²¡é”™ï¼Œè¿˜ä¸ä¸€æ ·ã€‚
é‚£ä¹ˆé—®é¢˜å°±å‡ºåœ¨resizeå‡½æ•°ä¸Šäº†ã€‚
å¦‚æœç›´æ¥è¾“å‡ºï¼Œä½ ä¼šå‘ç°ï¼Œæˆ‘çš„å¤©ï¼Œå·®è·å¥½å¤§å•Šï¼ï¼ï¼
éƒ½æ˜¯åŒçº¿æ€§å·®å€¼ï¼Œèƒ½å·®è·è¿™ä¹ˆå¤§ï¼Ÿ
å…¶å®è¿™é‡Œç¬¬ä¸€ä¸ªä¸åŒæ˜¯PILçš„å›¾åƒçŸ©é˜µä¸ºW\*H\*Cï¼Œè€ŒOpencvçš„æ˜¯H\*W\*Cï¼Œä¸è¿‡è¿™ä¸€ç‚¹å¹¶ä¸å½±å“ç½‘ç»œçš„è®¡ç®—ï¼Œå› ä¸ºåœ¨åé¢ç½‘ç»œè®¡ç®—ä¸­å·²ç»è€ƒè™‘è¿™ä¸€ç‚¹åŒºåˆ«äº†ï¼Œåœ¨Pytorchçš„ToTensoræ“ä½œä¸­å·²ç»è€ƒè™‘äº†è¿™ä¸€ç‚¹ï¼Œåœ¨å¯¹Numpyç±»å‹çš„æ•°æ®è¿›è¡Œè½¬æ¢æ—¶åšäº†ç›¸åº”çš„çŸ©é˜µå˜æ¢æ“ä½œã€‚çœŸæ­£å­˜åœ¨é—®é¢˜çš„æ˜¯PILè¯»å…¥çš„å›¾ç‰‡æ˜¯RGBæ’åˆ—çš„ä¸‰ä¸ªé€šé“ï¼Œè€ŒOpencvè¯»å…¥çš„æ˜¯BGRæ’åˆ—çš„ä¸‰ä¸ªé€šé“ã€‚è¿™é‡Œéœ€è¦æˆ‘ä»¬åœ¨ReadImageToCVMatå‡½æ•°çš„è¾“å‡ºå‰åŠ ä¸Šä¸€è¡Œï¼Œå¯ç ´æ­¤é˜µã€‚
```c++
cv::cvtColor(cv_img, cv_img, cv::COLOR_BGR2RGB);
```
å¯æ˜¯å³ä¾¿è¿™æ ·ï¼ŒRGBä¸‰é€šé“çš„è¾“å‡ºåƒç´ å·®åˆ«ä¹Ÿè¾ƒå¤§ã€‚ä¸‹é¢ç”»äº†ä¸‰å¼ åƒç´ å·®å€¼çš„åˆ†å¸ƒå›¾ï¼š
Rï¼š
![R](https://i.loli.net/2019/03/08/5c82423f1f783.png)
Gï¼š
![G](https://i.loli.net/2019/03/08/5c82423f336af.png)
Bï¼š
![B](https://i.loli.net/2019/03/08/5c82423eab405.png)
æœ€å¤§çš„åå·®ç”šè‡³å¤§äº70ä¸ªåƒç´ ã€‚

è¿™æ ·æˆ‘ä»¬å¯èƒ½è¦æ­£é¢é¢å¯¹ä¸‰åƒå¤šè¡Œçš„opencvæºç äº†ã€‚ä½†æ˜¯PILå¦‚ä½•å®ç°çš„æˆ‘ä»¬å¹¶ä¸èƒ½çœ‹åˆ°ã€‚
è¿˜å¥½ï¼ŒPytorchå­˜åœ¨ä¸€å®šçš„äººæ€§ï¼ŒOpencvä¹Ÿæœ‰pythonçš„åº“ï¼Œcv2ã€‚æˆ‘ä»¬åªéœ€è¦åœ¨Pytorchè®­ç»ƒæ—¶ï¼Œä¸ä½¿ç”¨torchvisionæä¾›çš„å·¥å…·æ”¹å˜å›¾ç‰‡ï¼Œé¿å¼€PILåº“å³å¯ã€‚
å°†Pytorchçš„ä»£ç æ”¹ä¸ºï¼š
```python
img = cv2.imread('American_Redstart_0064_103081.jpg')
img = cv2.resize(img, (224,224))
img_t = transforms.Compose([transforms.ToTensor()])(img)
```
è‡ªæ­¤å¯ä»¥ä¿è¯é€å…¥ç½‘ç»œçš„æ•°æ®å®Œå…¨ä¸€æ ·ï¼








